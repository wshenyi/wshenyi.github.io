<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_16x16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wshenyi.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Godway&#39;s Notebook">
<meta property="og:url" content="https://wshenyi.github.io/index.html">
<meta property="og:site_name" content="Godway&#39;s Notebook">
<meta property="og:locale">
<meta property="article:author" content="Godway">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wshenyi.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'default'
  };
</script>

  <title>Godway's Notebook</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Godway's Notebook</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">wsy</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/WSHENYI/WSHENYI.github.io" class="github-corner" title="Star me on GitHub" aria-label="Star me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="">
    <link itemprop="mainEntityOfPage" href="https://wshenyi.github.io/2022/01/16/R17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.ico">
      <meta itemprop="name" content="Godway">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Godway's Notebook">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/16/R17/" class="post-title-link" itemprop="url">017 "Improving GPU Performance via Large Warps and Two-Level Warp Scheduling"</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-16 08:13:14" itemprop="dateCreated datePublished" datetime="2022-01-16T08:13:14-05:00">2022-01-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-17 00:48:25" itemprop="dateModified" datetime="2022-01-17T00:48:25-05:00">2022-01-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reviews/" itemprop="url" rel="index"><span itemprop="name">Reviews</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em><strong>Keywards</strong></em> GPGPU, SIMD, Divergence, Warp Scheduling</p>
<blockquote>
<p>Author: Veynu Narasiman, Michael Shebanow, Chang Joo Lee, Rustam Miftakhutdinov, Onur Mutlu, Yale N. Patt</p>
</blockquote>
<hr>
<h2 id="What-is-the-Problem"><a href="#What-is-the-Problem" class="headerlink" title="What is the Problem?"></a>What is the Problem?</h2><p>Altough GPUs achieve Thread Level Parallelism (TLP) through warp execution and concurrently executing manny warps on single GPU core (SM), the computational resources on GPU are still underutilized.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Threads on GPU are grouped into fixed-size SIMD batched known as warps and many warps are concurrently executed on a single GPU core. Despite this, computationaly resources on GPU cores are still underutillized. To further improve GPU performance, the authors propose two independent ideas: the large warp microarchitecture and two-level warp scheduling.</p>
<h2 id="Contribution-Key-Results"><a href="#Contribution-Key-Results" class="headerlink" title="Contribution / Key Results"></a>Contribution / Key Results</h2><p>Their mechanisms signifi-cantly improve computational resource utilization, resulting in 19.1% performance improvement over traditional GPU cores on a set of general purpose parallel applications.</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>GPUs expliot TLP in two major way:</p>
<ol>
<li>threads executing in fixed-size batches known as warps.</li>
<li>concurrently execute many warps on a singe core to hide execution latency.</li>
</ol>
<p>Two resouce for underutilization of computational resource:</p>
<ol>
<li>branch divergence due to conditional branch in the code.</li>
<li>unable to effectively hide latency of long latency operations.</li>
</ol>
<h2 id="Key-Insights"><a href="#Key-Insights" class="headerlink" title="Key Insights"></a>Key Insights</h2><ul>
<li>Large warp microarchitecture</li>
<li>Two-level warp scheduling</li>
</ul>
<h2 id="Limitations-Weaknesses"><a href="#Limitations-Weaknesses" class="headerlink" title="Limitations/Weaknesses"></a>Limitations/Weaknesses</h2><ul>
<li>The assumptions about default warp scheduling on GPU is round-robin may not be correct.</li>
<li>For data intensive application, the two level round-robin scheduling may not bring much performance improvement.</li>
<li>The hardware cost for implmentation their methods may not worth it because small improvemence is only improved on specific applications.</li>
</ul>
<h2 id="Open-Questions-Where-to-go-from-here"><a href="#Open-Questions-Where-to-go-from-here" class="headerlink" title="Open Questions [Where to go from here?]"></a>Open Questions [Where to go from here?]</h2><ul>
<li>How their methods apply to three dimentional grid?</li>
<li>In practice, the active mask may not be as sparse as they shown in the paper.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="">
    <link itemprop="mainEntityOfPage" href="https://wshenyi.github.io/2022/01/15/R16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.ico">
      <meta itemprop="name" content="Godway">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Godway's Notebook">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/15/R16/" class="post-title-link" itemprop="url">016 "General-Purpose Graphics Processor Architectures"</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-15 08:11:53" itemprop="dateCreated datePublished" datetime="2022-01-15T08:11:53-05:00">2022-01-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-16 22:33:58" itemprop="dateModified" datetime="2022-01-16T22:33:58-05:00">2022-01-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reviews/" itemprop="url" rel="index"><span itemprop="name">Reviews</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em><strong>Keywards</strong></em> GPGPU, computer architecture</p>
<blockquote>
<p>Author: Tor M. Aamodt, Wilson Wai Lun Fung, Timothy G. Rogers</p>
</blockquote>
<hr>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Over succeeding generations of products, GPU manufacturer’s have refined the GPU architecture and programming model to <strong>increase flexibility</strong> while simultaneously <strong>improving energy efficiency</strong>.</p>
<p>A typical system containing GPU is divided into two forms: 1. discrete CPU and GPU; 2. integrated CPU and GPU</p>
<img src="/2022/01/15/R16/1.png" class="">

<p>For distrete GPU, the DRAM technology used for CPU and GPU is different(<strong>DDR</strong> for CPU vs. <strong>GDDR</strong> for GPU). DDR for <em>Double Data Rate</em> and GDDR for Graphics DDR. The CPU DRAM is typically optimized for <strong>low latency access</strong> whereas the GPU DRAM is optimized for <strong>high throughput</strong>. For integrated GPU, as they are often found on low-powper mobile device, the shared DRAM memory it uses is often optimized for <strong>low power</strong> such as <strong>LPDDR</strong>.</p>
<p>A generic model GPU architecture, <strong>SIMT</strong></p>
<img src="/2022/01/15/R16/2.png" class="">

<p>GPUs can obtain improved performance per unit area vs. superscalar out-of-order CPUs on highly parallel workloads by dedicating a larger fraction of their die area to arithmetic logic units and correspondingly less area to control logic. Below is an analytical model-based analysis of the performance tradeoff between multicore (MC) CPU architectures and multithreaded (MT) architectures such as GPU.</p>
<img src="/2022/01/15/R16/3.png" class="">

<p>As the number of threads increases from the middle point, performance increases with the ability of multithreading to hide long off-chip latency. GPUs are designed to tolerate frequent cache misses by employing multithreading.</p>
<h2 id="Programming-Model"><a href="#Programming-Model" class="headerlink" title="Programming Model"></a>Programming Model</h2><p>A well-known operation <strong>SAXPY</strong> represent for <em>single-precision scalar value <strong>A</strong> times vector value <strong>X</strong> plus vector value <strong>Y</strong></em></p>
<p>Currently, NVIDIA warps consists of 32 threads while AMD wavefronts consist of 64 threads.</p>
<p>NVIDIA has introduced <strong>Unified Memory</strong>, which transparently updates GPU memory from CPU memory and CPU memory from GPU memory.</p>
<p>NVIDIA’s PTX(Parallel Thread Execution ISA) is many ways similar to a standard reduced instruction set computer (RISC) instruction set architecture. It also shares a similarity to the intermediate representations (IR) used within optimizing compilers.</p>
<p>Before running PTX code on the GPU it is necessary to compile PTX down to the actual instruction set architecture supported by the hardware. NVIDIA calls this level <strong>SASS</strong> which is short for “Streaming ASSembler”. The process ofconverting from PTX to SASS can be accomplished either by the GPU driver or a stand-alone program called <em>ptxas</em> provided with NVIDIA’s CUDA Toolkit.</p>
<h2 id="The-SIMT-core-Instruction-and-Register-Data-Flow"><a href="#The-SIMT-core-Instruction-and-Register-Data-Flow" class="headerlink" title="The SIMT core: Instruction and Register Data Flow"></a>The SIMT core: Instruction and Register Data Flow</h2><p>An <strong>approximating</strong> microarchitecture of a generic GPGPU core.</p>
<img src="/2022/01/15/R16/4.png" class="">

<p>The pipeline can be divided into a <strong>SIMT front-end</strong> and a <strong>SIMD back-end</strong>. The pipeline consists of three scheduling “loops” acting together in a single pipeline: 1. an <strong>instruction fetch</strong> loop, 2. an <strong>instruction issue</strong> loop, and 3. a <strong>register access</strong> scheduling loop.</p>
<h3 id="1-Instruction-Fetch-Loop"><a href="#1-Instruction-Fetch-Loop" class="headerlink" title="1. Instruction Fetch Loop"></a>1. Instruction Fetch Loop</h3><p>To increase efficiency, threads are organized into groups called “warps” by NVIDIA and “wavefronts” by AMD. Thus, <strong>the unit of scheduling is a warp</strong>.</p>
<p>After fetching an instruction, the instruction is decoded and source operand registers are fetched from the register file. In parallel with fetching source operands from the register file, the SIMT execution mask values are determined.</p>
<p>As in modern CPU designs, the <strong>function units</strong> are typically heterogeneous meaning a given function unit supports only a subset ofinstructions. For example, NVIDIA GPUs contain a <em>specialfunction unit</em> (SFU), <em>load/store unit, floating-point function unit, integer function unit</em>, and, as of Volta, a <em>Tensor Core</em>.</p>
<p>SIMT execution model presents the programmer with the abstraction that individual threads execute completely independently. However, in current GPUs it is achieved via a combination of traditional <em>predication</em> along with a stack of predicate masks that we shall refer to as the <strong>SIMT stack</strong>.</p>
<p>The SIMT stack helps efficiently handle two key issues: nested control flow and skipped computation.</p>
<p>A <strong>reconvergence point</strong> is a location in the program where threads that diverge can be forced to continue executing in lock-step.</p>
<p>The stack-based implementation of SIMT can lead to a deadlock condition called “<strong>SIMT deadlock</strong>”.</p>
<p>NVIDIA ‘s new thread divergence management approach is called <em>Independent Thread Scheduling</em> and it can fix SIMT deadlock by introducing a new structure <em>covergence barrier</em>. In contrast to a stack-based SIMT implementation, with convergence barrier implementation the scheduler is free to switch between groups of diverged threads.</p>
<img src="/2022/01/15/R16/5.png" class="">

<p>Each core in a GPU hosts contains many warps. To enable a different warp to issue an instruction <strong>each cycle</strong>, it is necessary that each thread have its own registers (avioding <em>context switch</em> occured in traditional CPU). The tradeoff is: <strong>increasing the number of warps per core increases the fraction of chip area devoted to register file storage relative to the fraction dedicated to execution units</strong>. (For a fixed chip area increasing warps per core will decrease the total nymber of cores per chip.)</p>
<h3 id="2-Instruction-Issue-Loop"><a href="#2-Instruction-Issue-Loop" class="headerlink" title="2. Instruction Issue Loop"></a>2. Instruction Issue Loop</h3><p>To help reduce the number of warps that each core must support to hide long execution latencies, it is helpful to be able to <strong>issue a subsequent instruction from a warp while earlier instructions have not yet completed</strong>. Thus, supporting many warps per core can help hide long execution latencies.</p>
<p>GPUs implement an instruction buffer were instructions are placed after cache access. A separate scheduler is used to decide which of several instructions in the instruction buffer should be issued next to the rest of the pipeline.</p>
<p>There are two traditional approaches to detecting <strong>dependencies</strong> between instructions found in traditional CPU architecture: <em>scoreboard</em> and <em>reservation stations</em>. (bty, scoreboards support out-of-order execution.)</p>
<p>Given it is the simplest design and therefore will consume the least amount of area and energy, GPUs implement <strong>in-order scoreboards</strong>.</p>
<h3 id="3-Register-Access-Scheduling-Loop"><a href="#3-Register-Access-Scheduling-Loop" class="headerlink" title="3. Register Access Scheduling Loop"></a>3. Register Access Scheduling Loop</h3><p>To hide long memory latencies it is necessary to support many warps per core and to support cycle by cycle switching between warps it is necessary to have a large register file that contains separate physical registers for every warp that is executing. One way to reduce the area of the register file is to simulate the large number of ports using multiple <strong>banks</strong> of single-ported memories. In some GPUs, this kind of structure is known as the <strong>operand collector</strong>.</p>
<p>Operand collector microarchitecture</p>
<img src="/2022/01/15/R16/6.png" class="">

<p>Each collector unit contains buffering space for all source operands required to execute an instruction. The operand collector uses scheduling to tolerate <strong>bank conflicts</strong> when they occur.</p>
<p>Some CPUs speculative wake up instructions depending upon a load so as to improve single threaded performance. In contrast, GPUs avoid <strong>speculation</strong> as it tends to waste energy and reduce throughput. Instead, <strong>instruction replay</strong> is used in GPUs to avoid clogging the pipeline and the circuit area and/or timing overheads resulting from stalling.</p>
<h2 id="Memory-System"><a href="#Memory-System" class="headerlink" title="Memory System"></a>Memory System</h2><p><strong>Pipeline hazards can be handled by replaying instructions</strong>.</p>
<p><strong>Shared memory</strong> in CUDA (or local memory in OpenCL) and <strong>L1 cache</strong> is a same thing except shared memory is controlled by programmer whereas L1 cache is controlled by hardware. They are implemented as a static random access memory (SRAM).</p>
<p>Below is an <em>unified L1 data cache and shared memory</em> architecture. #5 is an SRAM data array which can be configured partly for <strong>direct mapped access</strong> for shared memory and partly as a set associative cache.</p>
<img src="/2022/01/15/R16/7.png" class="">

<p>There are three kinds of opertions to this architecture: shared memory access operations, cache read operations, cache write operations.</p>
<p>The SIMT cores connect to the memory partition units via an on-chip interconnection network. For NVIDIA it’s called <strong>crossbar</strong>, and for AMD it’s called <strong>ring network</strong>.</p>
<p>Refer to the abstraction architecture shown above in section 1, <strong>Memory Partition Unit</strong> is under interconnect network. Each memory partition unit contains a portion of the <strong>second-level (L2) cache</strong> along with a one or more memory access schedulers also called a “frame buffer,” or <strong>FB</strong>, and a raster operation (<strong>ROP</strong>) unit. The L2 cache contains both graphics and compute data.</p>
<img src="/2022/01/15/R16/8.png" class="">

<p>The ROP unit includes function units for executing atomic and reduction operations.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="">
    <link itemprop="mainEntityOfPage" href="https://wshenyi.github.io/2022/01/02/R3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.ico">
      <meta itemprop="name" content="Godway">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Godway's Notebook">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/02/R3/" class="post-title-link" itemprop="url">003 "Viewpoint Accelerator-Level Parallelism"</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-02 20:04:12" itemprop="dateCreated datePublished" datetime="2022-01-02T20:04:12-05:00">2022-01-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-15 18:18:55" itemprop="dateModified" datetime="2022-01-15T18:18:55-05:00">2022-01-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reviews/" itemprop="url" rel="index"><span itemprop="name">Reviews</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em><strong>Keywards</strong></em> review, accelerator-level parallelism</p>
<blockquote>
<p>Author: Mark D. Hill and Vijay Janapa Reddi</p>
</blockquote>
<hr>
<h2 id="What-is-the-Problem"><a href="#What-is-the-Problem" class="headerlink" title="What is the Problem?"></a>What is the Problem?</h2><p>Recent work on accelerators has focused on CPUs using a single accelerator in a specific application domains. The authors point out that many future computing systems will obtain greater efficiency by employing multiple different task-specific accelerators.</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p><strong>Accelerator</strong>: <em>hardware components that execute a targeted computation class faster and usually with much less energy</em>.</p>
<p>An accelerator’s flexibility can vary from high (GP-GPU) to low (fixed-function block).</p>
<p>Below is a snapshot of parallelism over the years:</p>
<img src="/2022/01/02/R3/1.png" class="">

<h2 id="Key-Insights"><a href="#Key-Insights" class="headerlink" title="Key Insights"></a>Key Insights</h2><ul>
<li>Definition of a Accelerator Level Parallelism (ALP): <em>the parallelism of workload components concurrently executing on multiple accelerators</em>.</li>
<li>ALP opens up many degrees of freedom for novel hardware and software design and optimization.</li>
<li>Mobile SoCs as harbingers of multiple accelerators using ALP.</li>
</ul>
<h2 id="Challenges-and-Future"><a href="#Challenges-and-Future" class="headerlink" title="Challenges and Future"></a>Challenges and Future</h2><p>A key challenge is developing abstractions and implementations to enable programmers to target the whole SoC and implementers to holistically design its software and hardware. (like SIMT model)</p>
<ul>
<li>Today’s SoCs only exploit ALP in limited niches with each accelerator acting seperately with its own programming model, and often its own (domian-specific) language, runtime, software development kit (SDK), and dtiver interface.</li>
<li>ALP exploitation will likely require software-hardware co-design due to the heterogeneous nature of accelerators and ALP. A collection of locally optimal accelerators is unlikely to be globally optimal.</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Employing mutiple accelerators with ALP has much promise for enhanting future computing efficiency. The authors have identified <em>what</em> the opportunity is, but leave to readers <em>how</em> best to solve it.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="">
    <link itemprop="mainEntityOfPage" href="https://wshenyi.github.io/2022/01/01/R2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.ico">
      <meta itemprop="name" content="Godway">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Godway's Notebook">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/01/R2/" class="post-title-link" itemprop="url">002 "Near-memory computing:Past, present, and future"</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-01 21:04:13" itemprop="dateCreated datePublished" datetime="2022-01-01T21:04:13-05:00">2022-01-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-15 18:19:04" itemprop="dateModified" datetime="2022-01-15T18:19:04-05:00">2022-01-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reviews/" itemprop="url" rel="index"><span itemprop="name">Reviews</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em><strong>Keywards</strong></em> Near-memory computing, Data-centric computing, Modeling, Computer architecture, Application characterization,Survey</p>
<blockquote>
<p>Author: Gagandeep Singh, Lorenzo Chelini, Stefano Corda, Ahsan Javed Awan, Sander Stuijk, Roel Jordans, Henk Corporaal, Albert-Jan Boonstra</p>
</blockquote>
<hr>
<h2 id="What-is-the-Problem"><a href="#What-is-the-Problem" class="headerlink" title="What is the Problem?"></a>What is the Problem?</h2><p>Today’s memory hierarchy usually consists of multiple levels of cache. However, in data-intensive applications,<br> frequent data movement between the memory subsystem and the processor can be expensive, leading to a severe impact on performance and energy efficiency. <strong>Near-memory computing</strong> (NMC) aims at processing close to where the data resides.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>The convential approach of moving data to the CPU for computation has become a significant performance bottleneck for emerging scale-out data-intensive applications due to their limited data reuse. At the same time, the advancement in 3D integration technologies has made <strong>near-memory computing</strong> (NMC) more viable. This paper aims to analyze and organize the extensive body of literature related to the novel area of near-memory computing.</p>
<h2 id="Contribution-Key-Results"><a href="#Contribution-Key-Results" class="headerlink" title="Contribution / Key Results"></a>Contribution / Key Results</h2><ul>
<li>They analyze and organize the body of literature on near-memory computing under various dimensions.</li>
<li>They provide guidelines for design space exploration.</li>
<li>They present our near-memory system outlining application characterization and compiler framework. Also, we include an analytic model to illustrate the potential of near-memory computing for memory intensive application with a comparison to the current CPU-centric approach.</li>
<li>They outline the directions for future research and highlight current challenges.</li>
</ul>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Classification of computing systems based on working set location. NMC bring processing core to the place where data resides. Computation-in-memory further reduces data movement by using memories with compute capability (e.g. memristors, phase change memory).</p>
<img src="/2022/01/01/R2/1.png" class="">

<h2 id="Key-Insights"><a href="#Key-Insights" class="headerlink" title="Key Insights"></a>Key Insights</h2><p>The resurgence of NMC is largely attributed to following three reasons:</p>
<ol>
<li>technological advancement in 3D and 2.5D stacking that blends logic and memory in the same package.</li>
<li>NMC can sidestep the performance and energy bottlenecks due to data movement by circumventing memory-package pin-count limitations.</li>
<li>Data-intensive applications call for newer architectures.</li>
</ol>
<h2 id="Challenges-of-NMC"><a href="#Challenges-of-NMC" class="headerlink" title="Challenges of NMC"></a>Challenges of NMC</h2><ol>
<li>Virtual memory support</li>
<li>Cache coherence</li>
<li>Programming model</li>
<li>Data mapping</li>
</ol>
<h2 id="Open-Issues-and-Future-Directions"><a href="#Open-Issues-and-Future-Directions" class="headerlink" title="Open Issues and Future Directions"></a>Open Issues and Future Directions</h2><ul>
<li>It is unclear which emerging memory technology best supports near-memory architectures.</li>
<li>3D stacking also needs unique power and thermal solutions, as traditional heat sink technology would not suffice if we want to add more computation close to the memory. Most of the proposed architectures do not take into account the strict power budget of 3D stacked memories, which limits the architecture’s practicality.</li>
<li>DRAM and NVM have different memory attributes.</li>
<li>Most of the evaluated architectures focus on the compute aspect. Lack of coherency and virtual support makes programming difficult and obstructs the adoption of this paradigm.</li>
<li>More quantitative exploration is required for interconnect networks between the near-memory compute units and also between the host and near-memory compute system.</li>
<li>At the application level, algorithms need to provide code and data co-location for energy efficient processing.</li>
<li>The field requires a generic set of open-source tools and techniques for these novel systems, as often researchers have to spend a significant amount of time and effort in building the needed simulation environment.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="">
    <link itemprop="mainEntityOfPage" href="https://wshenyi.github.io/2021/12/31/R1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.ico">
      <meta itemprop="name" content="Godway">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Godway's Notebook">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/31/R1/" class="post-title-link" itemprop="url">001 "Bounded Model Checking"</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-31 10:12:43" itemprop="dateCreated datePublished" datetime="2021-12-31T10:12:43-05:00">2021-12-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-15 18:19:10" itemprop="dateModified" datetime="2022-01-15T18:19:10-05:00">2022-01-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reviews/" itemprop="url" rel="index"><span itemprop="name">Reviews</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em><strong>Keywards</strong></em> bounded model checking</p>
<blockquote>
<p>Author: Armin Biere, Alessandro Cimatti, Edmund M. Clarke, Ofer Strichman, Yunshan Zhu</p>
</blockquote>
<hr>
<h2 id="What-is-the-Problem"><a href="#What-is-the-Problem" class="headerlink" title="What is the Problem?"></a>What is the Problem?</h2><p>Although numerous techiques such as decomposition, abstraction and various reductions have been proposed to tackle the memory explosion problem of BDD-based model checking, full verification of many designs is still beyond the capacity of BDD-based symbolic model checkers.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>The authors survey a technique called Bounded Model Checking (BMC), which uses a propositional SAT solver rather than BDD manipulation techniques. Experiments have shown that BMC can solve many cases that cannot be solved by BDD-based techniques. The converse is also true: there are also some problems that BMC can’t solve. Therefore, BMC is regraded as a complementary techqiue to BDD-based symbolic model checking.</p>
<h2 id="Contribution-Key-Results"><a href="#Contribution-Key-Results" class="headerlink" title="Contribution / Key Results"></a>Contribution / Key Results</h2><p>A great comprehensive review for <strong>bounded model checking</strong> (BMC) technique.</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>In model checking, the design to be verified is modeled as a finite state machine, and the specification is formalized by writing <em>temporal logic</em> properties.</p>
<p>In general, properties are classified to ‘<strong>safety</strong>‘ and ‘<strong>liveness</strong>‘ properties.</p>
<ul>
<li>Safety: what should not happen (or what should always happen). =&gt; decribe <strong>invariants</strong> of a system</li>
<li>Liveness: what should happen.</li>
</ul>
<p>In case the property fails, a comterexample is generated in the form of a sequence of states.</p>
<ul>
<li>A counterexample of safety properties is a trace of states, where the last state contradict the property.</li>
<li>A counterexample to liveness properties, in its simplest form, is a path to a loop that does not contain the desired state.</li>
</ul>
<p>There is no such thing as a ‘correct system’; it is only possible to check whether a system satisfies its specification or not.</p>
<p>Users of model checking tools typically consider it as <strong>complimentary</strong> to the more traditional methods of <strong>testing and simulation</strong>, and not as an <strong>alternative</strong>.</p>
<p>Model Checking (MC) uses <em>explicit state representation</em> when it is first proposed. However, explicit representation restrict the capacity of model checkers to systems with a few million states. This makes MC impossible to sacle to examples with inductrial complexity. The introduction of <em>symbolic model checking</em> made the first breakthrough towards wide usage of MC techiques. In symbolic model checking, sets of states are represented implicitly using <em>Boolean functions</em>. Manipulating boolean formulas can be done efficiently with Reduced Ordered Binary Decision Diagrams (ROBDD). The combination of symbolic model checking with BDDs, pushed the barrier to systems with $10^{20}$ states and more.</p>
<p>The bottleneck of these methods is the amount of memory that is required for storing and manipulating BDDs.</p>
<h2 id="Model-Checking-and-LTL"><a href="#Model-Checking-and-LTL" class="headerlink" title="Model Checking and LTL"></a>Model Checking and LTL</h2><p>Model checking has three fundamental features:</p>
<ol>
<li>it is automatic</li>
<li>the system are assumed to be finite (though using abstration techniques can process infinite space.)</li>
<li>temporal logic (LTL, CTL, CTL*) is used for specifying the system properties.</li>
</ol>
<p><strong>Model checking can be summarized as an algorithm technique for checking temporal properties of finite systems</strong>.</p>
<img src="/2021/12/31/R1/1.png" class="">

<ul>
<li>The <em>Globally</em> operator $G$ is used for <strong>safety property</strong></li>
<li>The <em>Finally</em> operator $F$ is used for <strong>liveness property</strong></li>
</ul>
<p>A temporal formula $f$ holds for a Kripke structure $M$, written $M$ |= $f$, iff $\pi$ |= $f$ for all initialized paths $\pi$ of $M$.</p>
<h2 id="Bounded-Model-Checking"><a href="#Bounded-Model-Checking" class="headerlink" title="Bounded Model Checking"></a>Bounded Model Checking</h2><p>The original motivation of BMC was to leverage the success of SAT in solving Boolean formulas to model checking.</p>
<p>In BMC, the search for a plan is restricted to paths with some predetermined bound, which means the search is deterministic.</p>
<p>In <em>bounded sematics</em>, only a prefix with a back loop can represent a witness for <strong>G</strong>$p$. Even if $p$ holds along all the states from $s_0$ to $s_k$, since $p$ might not hold at $s_{k+1}$.</p>
<h2 id="Reducing-BMC-to-SAT"><a href="#Reducing-BMC-to-SAT" class="headerlink" title="Reducing BMC to SAT"></a>Reducing BMC to SAT</h2><p>Unroll transition relation $T$ upto some bound $k$.</p>
<p>The formula ${[ M, f ]}_k$ encodes constraints on $s_0,\ …\ s_k$ such that ${[ M, f ]}_k$ is satisfiable iff $\pi$ is a witness for $f$. The definition of formula ${[ M, f ]}_k$ has three seperate components:</p>
<ol>
<li>A propositional formula ${[M]}_k$ that constrains $s_0,\ …\ s_k$ to be a valid path starting from an initial state.</li>
<li><em>loop condition</em>, which is a propositional formula that is evaluated to true only if the path $\pi$ contains a loop.</li>
<li>A propositional formula tha constrains $\pi$ to satisfy $f$.</li>
</ol>
<h2 id="Techniques-for-Completeness"><a href="#Techniques-for-Completeness" class="headerlink" title="Techniques for Completeness"></a>Techniques for Completeness</h2><ol>
<li>Use <strong>Completeness Threshold</strong> as upper bound to guarantee the property holds</li>
<li>Liveness property: a semi-decision procedure for <strong>AF</strong>$p$ combined with a semi decision procedure for <strong>EG</strong>$p$.</li>
<li>Safety property: induction based on strengthening <strong>inductive invariants</strong>.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Godway"
      src="/images/avatar.ico">
  <p class="site-author-name" itemprop="name">Godway</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">40</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="/475865836@qq.com" title="E-Mail → 475865836@qq.com"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://randool.cn/" title="https:&#x2F;&#x2F;randool.cn" rel="noopener" target="_blank">Randool</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://me.csdn.net/Smile_coderrr" title="https:&#x2F;&#x2F;me.csdn.net&#x2F;Smile_coderrr" rel="noopener" target="_blank">Smile_coderrr</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Godway</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
